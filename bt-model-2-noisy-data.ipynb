{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1997093,"sourceType":"datasetVersion","datasetId":1194525}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport shutil\nimport numpy as np\nfrom tqdm import tqdm\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nimport torch.nn.functional as F\nfrom torch.cuda.amp import GradScaler, autocast\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, confusion_matrix, roc_auc_score\n\n# Function to add Gaussian noise to an image\ndef add_gaussian_noise(image, mean=0, std=0.1):\n    noise = torch.randn_like(image) * std + mean\n    noisy_image = torch.clamp(image + noise, 0., 1.)  # Ensure values are in the range [0, 1]\n    return noisy_image\n\n# File paths\nIMG_PATH = \"/kaggle/input/brain-tumor-detection-mri/Brain_Tumor_Detection/\"\nWORKING_DIR = '/kaggle/working/'\n\n# Image dimension and batch size\nDIM = 62\nbatch_size = 32\n\n# Directories for train, val, and test splits\nTRAIN_DIR = os.path.join(WORKING_DIR, 'TRAIN')\nVAL_DIR = os.path.join(WORKING_DIR, 'VAL')\nTEST_DIR = os.path.join(WORKING_DIR, 'TEST')\n\n# Reset directories\nfor directory in [TRAIN_DIR, VAL_DIR, TEST_DIR]:\n    if os.path.exists(directory):\n        shutil.rmtree(directory)\n    os.makedirs(directory)\n    os.makedirs(os.path.join(directory, 'YES'))\n    os.makedirs(os.path.join(directory, 'NO'))\n\n# Gather all image file paths\nall_images = []\nfor CLASS in ['yes', 'no']:\n    if CLASS not in [\"pred\"]:  # Exclude the \"pred\" folder\n        for img_file in os.listdir(os.path.join(IMG_PATH, CLASS)):\n            all_images.append((os.path.join(IMG_PATH, CLASS, img_file), CLASS.upper()))\n\n# Separate the images into YES and NO\nyes_images = [img for img in all_images if img[1] == 'YES']\nno_images = [img for img in all_images if img[1] == 'NO']\n\n# Shuffle images to ensure randomness\nnp.random.seed(42)\nnp.random.shuffle(yes_images)\nnp.random.shuffle(no_images)\n\n# Create imbalanced validation and test sets with 70% 'YES' and 30% 'NO'\nval_test_yes = yes_images[:int(0.38 * len(yes_images))]\nval_test_no = no_images[:int(0.38 * len(no_images))]\n\n# Split the YES and NO data for validation and test with 70% YES and 30% NO\nval_yes = val_test_yes[:int(0.5 * len(val_test_yes))]\nval_no = val_test_no[:int(0.5 * len(val_test_no))]\n\ntest_yes = val_test_yes[int(0.50 * len(val_test_yes)):]\ntest_no = val_test_no[int(0.50 * len(val_test_no)):]\n\n# Combine the validation and test sets\nval_images = val_yes + val_no\ntest_images = test_yes + test_no\n\n# Remaining images go to training set\ntrain_images = yes_images[int(0.38 * len(yes_images)):] + no_images[int(0.38 * len(no_images)):]\n\n# Shuffle the final sets to ensure randomness\nnp.random.shuffle(train_images)\nnp.random.shuffle(val_images)\nnp.random.shuffle(test_images)\n\n# Count the number of images in each dataset\nprint(f\"Number of training images: {len(train_images)}\")\nprint(f\"Number of validation images: {len(val_images)}\")\nprint(f\"Number of test images: {len(test_images)}\")\n\n# Copy images to respective directories\ndef copy_images(image_list, target_dir):\n    for img_path, label in image_list:\n        shutil.copy(img_path, os.path.join(target_dir, label, os.path.basename(img_path)))\n\ncopy_images(train_images, TRAIN_DIR)\ncopy_images(val_images, VAL_DIR)\ncopy_images(test_images, TEST_DIR)\n\n# Custom Dataset class that loads images on-the-fly\nclass MyDataset(Dataset):\n    def __init__(self, file_paths, transform=None, add_noise=False):\n        self.file_paths = file_paths\n        self.transform = transform\n        self.add_noise = add_noise\n\n    def __len__(self):\n        return len(self.file_paths)\n\n    def __getitem__(self, index):\n        img_path, label = self.file_paths[index]\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = cv2.resize(image, (DIM, DIM))\n        label = 1 if label == 'YES' else 0\n        if self.transform:\n            image = self.transform(image)\n        if self.add_noise:\n            image = add_gaussian_noise(image)\n        return image, label\n\n# Data augmentation and normalization for training\ntrans_train = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.RandomRotation(20),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Normalization for validation and test\ntrans_valid = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Datasets (Noise added for validation and test sets)\ndataset_train = MyDataset(train_images, transform=trans_train, add_noise=True)\ndataset_valid = MyDataset(val_images, transform=trans_valid, add_noise=True)\ndataset_test = MyDataset(test_images, transform=trans_valid, add_noise=True)\n\n# Dataloaders\nloader_train = DataLoader(dataset=dataset_train, batch_size=batch_size, shuffle=True, num_workers=2)\nloader_valid = DataLoader(dataset=dataset_valid, batch_size=batch_size // 2, shuffle=False, num_workers=2)\nloader_test = DataLoader(dataset=dataset_test, batch_size=batch_size // 2, shuffle=False, num_workers=2)\n\n# Define the image dimension and hyperparameters\nnum_epochs = 300\nbatch_size = 52\naccumulation_steps = 4\nlearning_rate = 0.0008\n\n# Define the model and layers\nclass FuzzyAtrousConv(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size=3, dilation=2, padding=1):\n        super(FuzzyAtrousConv, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, dilation=dilation, padding=padding)\n        self.bn = nn.BatchNorm2d(out_channels)\n\n    def fuzzy_membership(self, x):\n        high_membership = torch.sigmoid(x)\n        low_membership = torch.sigmoid(-x)\n        return high_membership, low_membership\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        high_membership, low_membership = self.fuzzy_membership(x)\n        x = high_membership * x + low_membership * (1 - x)\n        x = F.relu(x)\n        return x\n\nclass TOFU(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(TOFU, self).__init__()\n        self.conv1 = FuzzyAtrousConv(in_channels, 16, kernel_size=3, dilation=2, padding=2)\n        self.conv2 = FuzzyAtrousConv(16, 32, kernel_size=3, dilation=2, padding=2)\n        self.conv3 = FuzzyAtrousConv(32 + 16, 48, kernel_size=3, dilation=2, padding=2)\n        self.compress = nn.Conv2d(48 + 32 + 16, out_channels, kernel_size=1)\n        self.bn = nn.BatchNorm2d(out_channels)\n\n    def forward(self, inputs):\n        x1 = self.conv1(inputs)\n        x2 = self.conv2(x1)\n        x3 = self.conv3(torch.cat([x1, x2], dim=1))\n        x4 = F.relu(self.compress(torch.cat([x1, x2, x3], dim=1)))\n        x4 = self.bn(x4)\n        return x4\n\nclass MOFU(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(MOFU, self).__init__()\n        self.conv1 = FuzzyAtrousConv(in_channels, 16, kernel_size=3, dilation=2, padding=2)\n        self.conv2 = FuzzyAtrousConv(16, 32, kernel_size=3, dilation=2, padding=2)\n        self.conv3 = FuzzyAtrousConv(32, out_channels, kernel_size=3, dilation=2, padding=2)\n        self.bn = nn.BatchNorm2d(out_channels)\n\n    def forward(self, inputs):\n        x = self.conv1(inputs)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = self.bn(x)\n        return x\n\nclass Net(nn.Module):\n    def __init__(self, num_classes=1):\n        super(Net, self).__init__()\n        self.initial_conv = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n        self.initial_bn = nn.BatchNorm2d(32)\n        self.tofu1 = TOFU(in_channels=32, out_channels=64)\n        self.tofu2 = TOFU(in_channels=64, out_channels=128)\n        self.mofu = MOFU(128, 256)\n        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc1 = nn.Linear(256, 128)\n        self.fc2 = nn.Linear(128, num_classes)\n\n    def forward(self, x):\n        x = F.relu(self.initial_bn(self.initial_conv(x)))\n        x = self.tofu1(x)\n        x = self.tofu2(x)\n        x = self.mofu(x)\n        x = self.global_avg_pool(x).reshape(x.size(0), -1)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, p=0.2, training=self.training)\n        x = self.fc2(x)\n        return x\n\n# Initialize and set up PyTorch model, loss, optimizer\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = Net(num_classes=1).to(device)\n\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\nscheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=20, verbose=True)\nscaler = GradScaler()\n\n# Training and evaluation functions with mixed precision and gradient accumulation\ndef train_one_epoch(epoch, model, criterion, optimizer, dataloader, scaler, accumulation_steps):\n    model.train()\n    running_loss = 0.0\n    correct_preds = 0\n    total_samples = 0\n    \n    optimizer.zero_grad()\n    \n    for i, (images, labels) in enumerate(dataloader):\n        images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n        \n        with autocast():\n            outputs = model(images)\n            loss = criterion(outputs, labels) / accumulation_steps\n        \n        scaler.scale(loss).backward()\n        \n        if (i + 1) % accumulation_steps == 0:\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad()\n        \n        running_loss += loss.item() * images.size(0) * accumulation_steps\n        predicted = torch.round(torch.sigmoid(outputs))\n        correct_preds += (predicted == labels).sum().item()\n        total_samples += labels.size(0)\n        \n    epoch_loss = running_loss / len(dataloader.dataset)\n    epoch_accuracy = correct_preds / total_samples\n    \n    print(f'Epoch [{epoch}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')\n    return epoch_loss, epoch_accuracy\n\ndef evaluate(model, criterion, dataloader):\n    model.eval()\n    running_loss = 0.0\n    correct_preds = 0\n    total_samples = 0\n    all_labels = []\n    all_preds = []\n    all_outputs = []\n    \n    with torch.no_grad():\n        for images, labels in dataloader:\n            images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            \n            running_loss += loss.item() * images.size(0)\n            predicted = torch.round(torch.sigmoid(outputs))\n            correct_preds += (predicted == labels).sum().item()\n            total_samples += labels.size(0)\n            \n            all_labels.extend(labels.cpu().numpy())\n            all_preds.extend(predicted.cpu().numpy())\n            all_outputs.extend(outputs.cpu().numpy())\n    \n    epoch_loss = running_loss / len(dataloader.dataset)\n    epoch_accuracy = correct_preds / total_samples\n    epoch_auc = roc_auc_score(all_labels, all_outputs)\n    \n    return epoch_loss, epoch_accuracy, epoch_auc, all_labels, all_preds\nos.makedirs('savedmodels', exist_ok=True)\n# Main training loop\nnum_epochs = 300\npatience = 20\nbest_val_loss = float('inf')\nbest_epoch = 0\ntrain_losses, val_losses, train_accuracies, val_accuracies, val_aucs = [], [], [], [], []\n\nfor epoch in range(num_epochs):\n    train_loss, train_accuracy = train_one_epoch(epoch + 1, model, criterion, optimizer, loader_train, scaler, accumulation_steps)\n    val_loss, val_accuracy, val_auc, val_labels, val_preds = evaluate(model, criterion, loader_valid)\n    \n    print(f'Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}, AUC: {val_auc:.4f}')\n    \n    train_losses.append(train_loss)\n    val_losses.append(val_loss)\n    train_accuracies.append(train_accuracy)\n    val_accuracies.append(val_accuracy)\n    val_aucs.append(val_auc)\n    \n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        best_epoch = epoch + 1\n        torch.save(model.state_dict(), f'savedmodels/best_model_epoch{best_epoch}.h5')\n    \n    if epoch - best_epoch >= patience:\n        print(\"Early stopping triggered\")\n        break\n    \n    scheduler.step(val_loss)\n\n# Final evaluation on test set\ntest_loss, test_accuracy, test_auc, test_labels, test_preds = evaluate(model, criterion, loader_test)\nprint(f'Test Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.4f}, AUC: {test_auc:.4f}')\n\n# Calculate metrics\nprecision = precision_score(test_labels, test_preds)\nrecall = recall_score(test_labels, test_preds)\nf1 = f1_score(test_labels, test_preds)\nkappa = cohen_kappa_score(test_labels, test_preds)\n\nprint(f'Test Precision: {precision:.4f}')\nprint(f'Test Recall: {recall:.4f}')\nprint(f'Test F1 Score: {f1:.4f}')\nprint(f'Test Cohen Kappa: {kappa:.4f}')\n\n# Plot confusion matrix\ncm = confusion_matrix(test_labels, test_preds)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['NO', 'YES'], yticklabels=['NO', 'YES'])\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()\n\n# Plot losses and accuracies\nepochs_range = range(1, len(train_losses) + 1)\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, train_losses, label='Train Loss')\nplt.plot(epochs_range, val_losses, label='Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.title('Loss Over Epochs')\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}